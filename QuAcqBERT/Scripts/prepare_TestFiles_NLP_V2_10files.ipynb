{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Files"
      ],
      "metadata": {
        "id": "Iui_PNUPqDWj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtoaRIEbb2CQ"
      },
      "outputs": [],
      "source": [
        "phrasesEqual = [\n",
        "    \"!ELM1! must have the same value as !ELM2!\",\n",
        "    \"!ELM1! should be identical to !ELM2!\",\n",
        "    \"!ELM1! needs to be on par with !ELM2!\",\n",
        "    \"!ELM1! is required to match !ELM2!\",\n",
        "    \"!ELM1! ought to be the same as !ELM2!\",\n",
        "    \"!ELM1! has to be equivalent to !ELM2!\",\n",
        "    \"!ELM1! necessitates being equal to !ELM2!\",\n",
        "    \"!ELM1! mandatory to be at par with !ELM2!\",\n",
        "    \"!ELM1! demands equality with !ELM2!\",\n",
        "    \"!ELM1! calls for an equal value as !ELM2!\"\n",
        "]\n",
        "phrasesNotEqual = [\n",
        "    \"!ELM1! must not be the same as !ELM2!\",\n",
        "    \"!ELM1! should not be identical to !ELM2!\",\n",
        "    \"!ELM1! need to differ from !ELM2!\",\n",
        "    \"!ELM1! ought to be distinct from !ELM2!\",\n",
        "    \"!ELM1! is required to be unlike !ELM2!\",\n",
        "    \"!ELM1! necessitates being dissimilar to !ELM2!\",\n",
        "    \"!ELM1! is mandatory to have variations from !ELM2!\",\n",
        "    \"!ELM1! is essential to have disparities from !ELM2!\",\n",
        "    \"!ELM1! is recommended to have contrasts with !ELM2!\",\n",
        "    \"!ELM1! is obligatory to exhibit differences from !ELM2!\"\n",
        "]\n",
        "phrasesGreaterThan = [\n",
        "    \"!ELM1! must exceed !ELM2!\",\n",
        "    \"!ELM1! Should surpass !ELM2!\",\n",
        "    \"!ELM1! needs to be higher than !ELM2!\",\n",
        "    \"!ELM1! ought to be greater than !ELM2!\",\n",
        "    \"!ELM1! necessitates being larger than !ELM2!\",\n",
        "    \"!ELM1! demands a higher value than !ELM2!\",\n",
        "    \"!ELM1! requires a greater amount than !ELM2!\",\n",
        "    \"!ELM1! mandatory to be above !ELM2!\",\n",
        "    \"!ELM1! essential to have a higher value than !ELM2!\",\n",
        "    \"!ELM1! compulsory to be greater than !ELM2!\"\n",
        "]\n",
        "phrasesGreaterorEqual = [\n",
        "    \"!ELM1! must not be less than !ELM2!\",\n",
        "    \"!ELM1! is required to have a value higher than or equal to !ELM2!\",\n",
        "    \"The minimum acceptable value of !ELM1! is !ELM2! or higher\",\n",
        "    \"Ensure !ELM1! is at least as great as !ELM2!\",\n",
        "    \"!ELM1! should not fall below !ELM2!\",\n",
        "    \"!ELM1! must meet or surpass !ELM2!\",\n",
        "    \"Make sure !ELM1! does not go beneath !ELM2!\"\n",
        "    \"!ELM1! ought to be no less than !ELM2!\",\n",
        "    \"!ELM1! should not be lower than !ELM2!\",\n",
        "    \"!ELM1! must adhere to !ELM2! or higher\"\n",
        "]\n",
        "\n",
        "phrasesLessThan = [\n",
        "    \"!ELM1! must not exceed !ELM2!\",\n",
        "    \"!ELM1! should not surpass !ELM2!\",\n",
        "    \"!ELM1! cannot go beyond !ELM2!\",\n",
        "    \"!ELM1! ought to be lower than !ELM2!\",\n",
        "    \"!ELM1! needs to be below !ELM2!\",\n",
        "    \"!ELM1! must remain under !ELM2!\",\n",
        "    \"!ELM1! should stay beneath !ELM2!\",\n",
        "    \"!ELM1! cannot surpass the limit of !ELM2!\",\n",
        "    \"!ELM1! ought to be smaller than !ELM2!\",\n",
        "    \"!ELM1! must be at a lower value than !ELM2!\"\n",
        "]\n",
        "phrasesLessorEqual = [\n",
        "    \"!ELM1! must not exceed or be equal to !ELM2!\",\n",
        "    \"Ensure !ELM1! remains at or below !ELM2!\",\n",
        "    \"!ELM1! cannot surpass or be equal to !ELM2!\",\n",
        "    \"!ELM1! should be limited to being equal to or less than !ELM2!\",\n",
        "    \"It is required that !ELM1! does not go beyond or be equal to !ELM2!\",\n",
        "    \"Keep !ELM1! below or equal to !ELM2!\",\n",
        "    \"!ELM1! should be constrained within !ELM2!, inclusive\",\n",
        "    \"!ELM1! must stay within or be less than or equal to !ELM2!\",\n",
        "    \"It is essential that !ELM1! does not exceed or be equal to !ELM2!\",\n",
        "    \"Ensure !ELM1! is equal to or less than !ELM2!\"\n",
        "]\n",
        "\n",
        "phrasesDistance = [\n",
        "    \"the space separating !ELM1! and !ELM2!\",\n",
        "    \"the gap amidst !ELM1! and !ELM2!\",\n",
        "    \"the extent of separation between !ELM1! and !ELM2!\",\n",
        "    \"the span from !ELM1! to !ELM2!\",\n",
        "    \"the measure of space between !ELM1! and !ELM2!\",\n",
        "    \"the interval that separates !ELM1! and !ELM2!\",\n",
        "    \"the length of the gap between !ELM1! and !ELM2!\",\n",
        "    \"the breadth of the divide between !ELM1! and !ELM2!\",\n",
        "    \"the scope of the distance from !ELM1! to !ELM2!\",\n",
        "    \"the expanse that lies between !ELM1! and !ELM2!\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Suduku"
      ],
      "metadata": {
        "id": "RV4dJjp2b6Jf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "calls= 0\n",
        "\n",
        "from random import random\n",
        "import numpy as np\n",
        "from itertools import combinations, permutations\n",
        "from math import *\n",
        "import operator\n",
        "import pickle\n",
        "import re\n",
        "\n",
        "n = 9\n",
        "vars_ids =   [i+1 for i in range(n**2)]\n",
        "vars_names = [\"X\"+ str(i+1) for i in range(n**2)]\n",
        "vars_types = [\"X\" for i in range(n**2)]\n",
        "vars_domains = [(1,n) for i in range(n**2)]\n",
        "types = [\"X\"]\n",
        "\n",
        "problem_data = {\n",
        "  id: {\n",
        "      \"domain\": vars_domains[id-1],\n",
        "       \"type\": vars_types[id-1],\n",
        "       \"name\": vars_names[id-1]\n",
        "  } for id in vars_ids\n",
        "}\n",
        "\n",
        "\n",
        "cpt = 0\n",
        "\n",
        "while(cpt<=9):\n",
        "  constraints = []\n",
        "  already = []\n",
        "\n",
        "  coords = []\n",
        "  line = 0\n",
        "\n",
        "  # lines :\n",
        "  m = []\n",
        "\n",
        "  for j in range(n):\n",
        "    l = []\n",
        "    for i in range(j*(int(sqrt(n))**2)+1, ((j+1)*(int(sqrt(n))**2))+1):\n",
        "      l.append(i)\n",
        "\n",
        "    m.append(np.array(l))\n",
        "    for p in combinations(l,2):\n",
        "      #print(\"p: \",p)\n",
        "      #constraints.append(Constraint(list(p), operator.ne, 2, True))\n",
        "      ri = cpt\n",
        "      if( p not in already and (p[1],p[0]) not in already):\n",
        "        already.append(p)\n",
        "        cons = re.sub(\"!ELM1!\",problem_data[p[0]][\"name\"],phrasesNotEqual[ri])\n",
        "        cons = re.sub(\"!ELM2!\",problem_data[p[1]][\"name\"],cons)\n",
        "        constraints.append(cons)\n",
        "        coords.append({\n",
        "            \"scope\": p,\n",
        "            \"rel\": operator.ne,\n",
        "            \"indice\": line\n",
        "        })\n",
        "        line+=1\n",
        "\n",
        "\n",
        "\n",
        "  #colomns\n",
        "  #print(\"\\n________________\\n\")\n",
        "  mm = np.array(m).T\n",
        "\n",
        "  for i in range(n):\n",
        "    l = []\n",
        "    for j in range(n):\n",
        "      l.append(mm[i][j])\n",
        "\n",
        "  #  print(l)\n",
        "    for p in combinations(l,2):\n",
        "      #constraints.append(Constraint([int(p[0]), int(p[1])], operator.ne, 2, True))\n",
        "      ri = cpt\n",
        "      if( p not in already and (p[1],p[0]) not in already):\n",
        "        already.append(p)\n",
        "        cons = re.sub(\"!ELM1!\",problem_data[p[0]][\"name\"],phrasesNotEqual[ri])\n",
        "        cons = re.sub(\"!ELM2!\",problem_data[p[1]][\"name\"],cons)\n",
        "        constraints.append(cons)\n",
        "        coords.append({\n",
        "            \"scope\": p,\n",
        "            \"rel\": operator.ne,\n",
        "            \"indice\": line\n",
        "        })\n",
        "        line+=1\n",
        "\n",
        "\n",
        "  blocks  = []\n",
        "  for k in range(0, n-int(sqrt(n))+1, int(sqrt(n))):\n",
        "    for l in range(0, n-int(sqrt(n))+1, int(sqrt(n))):\n",
        "      b = []\n",
        "      for i in range(k, k+int(sqrt(n))):\n",
        "        ll = []\n",
        "        for j in range(l, l+int(sqrt(n))):\n",
        "          #print(m[i][j])\n",
        "          ll.append(m[i][j])\n",
        "        b.append((ll))\n",
        "\n",
        "      bb = []\n",
        "      for i in range(len(b)):\n",
        "        for j in range(len(b)):\n",
        "          bb.append(b[i][j])\n",
        "\n",
        "      for p in combinations(bb,2):\n",
        "          #constraints.append(Constraint([int(p[0]),int(p[1])], operator.ne, 2, True))\n",
        "          ri = cpt\n",
        "          if( p not in already and (p[1],p[0]) not in already):\n",
        "            already.append(p)\n",
        "            cons = re.sub(\"!ELM1!\",problem_data[p[0]][\"name\"],phrasesNotEqual[ri])\n",
        "            cons = re.sub(\"!ELM2!\",problem_data[p[1]][\"name\"],cons)\n",
        "            constraints.append(cons)\n",
        "            coords.append({\n",
        "            \"scope\": p,\n",
        "            \"rel\": operator.ne,\n",
        "            \"indice\": line\n",
        "        })\n",
        "            line+=1\n",
        "\n",
        "      blocks.append(b)\n",
        "\n",
        "\n",
        "  with open(\"constraintsNLPsuduku\"+str(cpt+1)+\".txt\", \"w\") as f:\n",
        "    for c in range(len(constraints)):\n",
        "      if(c< len(constraints)-1):\n",
        "        f.write(constraints[c]+\"\\n\")\n",
        "      else:\n",
        "        f.write(constraints[c])\n",
        "\n",
        "  cpt+=1"
      ],
      "metadata": {
        "id": "zHCN0W1sdzk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"sudukuCoods.txt\", \"wb\") as f:\n",
        "  pickle.dump(coords, f)"
      ],
      "metadata": {
        "id": "WnLXn5-YevqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# jigsaw"
      ],
      "metadata": {
        "id": "ClsgnTb2gOUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "calls= 0\n",
        "\n",
        "from random import random\n",
        "from math import *\n",
        "\n",
        "n = 9\n",
        "vars_ids =   [i+1 for i in range(n**2)]\n",
        "vars_names = [\"X\"+ str(i+1) for i in range(n**2)]\n",
        "vars_types = [\"X\" for i in range(n**2)]\n",
        "vars_domains = [(1,n) for i in range(n**2)]\n",
        "types = [\"X\"]\n",
        "\n",
        "problem_data = {\n",
        "  id: {\n",
        "      \"domain\": vars_domains[id-1],\n",
        "       \"type\": vars_types[id-1],\n",
        "       \"name\": vars_names[id-1]\n",
        "  } for id in vars_ids\n",
        "}\n",
        "\n",
        "cpt = 0\n",
        "\n",
        "\n",
        "while(cpt<=9):\n",
        "  constraints = []\n",
        "  already = []\n",
        "\n",
        "  coords = []\n",
        "  line = 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # lines :\n",
        "  m = []\n",
        "\n",
        "  for j in range(n):\n",
        "    l = []\n",
        "    for i in range(j*(int(sqrt(n))**2)+1, ((j+1)*(int(sqrt(n))**2))+1):\n",
        "      l.append(i)\n",
        "\n",
        "    m.append(np.array(l))\n",
        "    for p in combinations(l,2):\n",
        "      #print(\"p: \",p)\n",
        "      #constraints.append(Constraint(list(p), operator.ne, 2, True))\n",
        "      ri = cpt\n",
        "      if( p not in already and (p[1],p[0]) not in already):\n",
        "        already.append(p)\n",
        "        cons = re.sub(\"!ELM1!\",problem_data[p[0]][\"name\"],phrasesNotEqual[ri])\n",
        "        cons = re.sub(\"!ELM2!\",problem_data[p[1]][\"name\"],cons)\n",
        "        constraints.append(cons)\n",
        "        coords.append({\n",
        "            \"scope\": p,\n",
        "            \"rel\": operator.ne,\n",
        "            \"indice\": line\n",
        "        })\n",
        "        line+=1\n",
        "\n",
        "\n",
        "\n",
        "  #colomns\n",
        "  #print(\"\\n________________\\n\")\n",
        "  mm = np.array(m).T\n",
        "\n",
        "  for i in range(n):\n",
        "    l = []\n",
        "    for j in range(n):\n",
        "      l.append(mm[i][j])\n",
        "\n",
        "  #  print(l)\n",
        "    for p in combinations(l,2):\n",
        "      #constraints.append(Constraint([int(p[0]), int(p[1])], operator.ne, 2, True))\n",
        "      ri = cpt\n",
        "      if( p not in already and (p[1],p[0]) not in already):\n",
        "        already.append(p)\n",
        "        cons = re.sub(\"!ELM1!\",problem_data[p[0]][\"name\"],phrasesNotEqual[ri])\n",
        "        cons = re.sub(\"!ELM2!\",problem_data[p[1]][\"name\"],cons)\n",
        "        constraints.append(cons)\n",
        "        coords.append({\n",
        "            \"scope\": p,\n",
        "            \"rel\": operator.ne,\n",
        "            \"indice\": line\n",
        "        })\n",
        "        line+=1\n",
        "\n",
        "\n",
        "\n",
        "  # blocks  = []\n",
        "  # for k in range(0, n-int(sqrt(n))+1, int(sqrt(n))):\n",
        "  #   for l in range(0, n-int(sqrt(n))+1, int(sqrt(n))):\n",
        "  #     b = []\n",
        "  #     for i in range(k, k+int(sqrt(n))):\n",
        "  #       ll = []\n",
        "  #       for j in range(l, l+int(sqrt(n))):\n",
        "  #         #print(m[i][j])\n",
        "  #         ll.append(m[i][j])\n",
        "  #       b.append((ll))\n",
        "\n",
        "  #     bb = []\n",
        "  #     for i in range(len(b)):\n",
        "  #       for j in range(len(b)):\n",
        "  #         bb.append(b[i][j])\n",
        "\n",
        "  #     for p in combinations(bb,2):\n",
        "  #         constraints.append(Constraint([int(p[0]),int(p[1])], operator.ne, 2, True))\n",
        "\n",
        "  #     blocks.append(b)\n",
        "\n",
        "  Shapes = [\n",
        "      [1,2,3,10,11,12,19,20,21],\n",
        "      [8,9,17,18,27,36,45,54,53],\n",
        "      [24,25,26,33,34,35,42,43,44],\n",
        "      [28,29,37,46,55,64,65,73,74],\n",
        "      [38,39,40,47,48,49,56,57,58],\n",
        "      [59,66,67,68,69,75,76,77,78],\n",
        "      [22,30,31,32,41,50,51,52,60],\n",
        "      [4,5,6,7,13,14,15,16,23],\n",
        "      [61,62,63,70,71,72,79,80,81]\n",
        "  ]\n",
        "\n",
        "  for sh in Shapes:\n",
        "    for p in combinations(sh,2):\n",
        "      #constraints.append(Constraint([int(p[0]),int(p[1])], operator.ne, 2, True))\n",
        "      ri = cpt\n",
        "      if( p not in already and (p[1],p[0]) not in already):\n",
        "        already.append(p)\n",
        "        cons = re.sub(\"!ELM1!\",problem_data[p[0]][\"name\"],phrasesNotEqual[ri])\n",
        "        cons = re.sub(\"!ELM2!\",problem_data[p[1]][\"name\"],cons)\n",
        "        constraints.append(cons)\n",
        "        coords.append({\n",
        "            \"scope\": p,\n",
        "            \"rel\": operator.ne,\n",
        "            \"indice\": line\n",
        "        })\n",
        "        line+=1\n",
        "\n",
        "\n",
        "  with open(\"constraintsNLPjigsaw\"+str(cpt+1)+\".txt\", \"w\") as f:\n",
        "    for c in range(len(constraints)):\n",
        "      if(c< len(constraints)-1):\n",
        "        f.write(constraints[c]+\"\\n\")\n",
        "      else:\n",
        "        f.write(constraints[c])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  cpt+=1"
      ],
      "metadata": {
        "id": "0MBSPPZMftA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"jigsawCoods.txt\", \"wb\") as f:\n",
        "    pickle.dump(coords, f)"
      ],
      "metadata": {
        "id": "4C3FT1kTgjK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zebra"
      ],
      "metadata": {
        "id": "Wsh72ab-g1-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Regular vars case\n",
        "\n",
        "calls= 0\n",
        "\n",
        "from random import random\n",
        "\n",
        "vars_ids =   [   1 ,   2   ,  3    ,  4     ,   5  ,  6  ,    7   ,   8 ,    9  ,   10  ,   11   ,  12 ,  13  ,  14          ,   15  ,  16     , 17       ,18        ,19          ,20        ,21  , 22, 23,24 ,25]\n",
        "vars_names = [\"red\",\"green\",\"ivory\",\"yellow\",\"blue\",\"dog\",\"snails\",\"fox\",\"horse\",\"zebra\",\"coffee\",\"tea\",\"milk\",\"orange juice\",\"water\",\"English\",\"Sparniad\",\"Ukranian\",\"Norwegian\",\"Japanese\",\"Old Gold\",\"Kools\",\"Chesterfields\",\"Lucky Strike\",\"Parliaments\"]\n",
        "vars_types = [\"color\",\"color\",\"color\",\"color\",\"color\",\"pet\",\"pet\",\"pet\",\"pet\",\"pet\",\"drink\",\"drink\",\"drink\",\"drink\",\"drink\",\"country\",\"country\",\"country\",\"country\",\"country\",\"brand\",\"brand\",\"brand\",\"brand\",\"brand\"]\n",
        "vars_domains = [(1,5),(1,5),(1,5),(1,5),(1,5),(1,5),(1,5),(1,5),(1,5),(1,5),(1,5),(1,5),(1,5),(1,5),(1,5),(1,5),(1,5),(1,5),(1,5),(1,5),(1,5),(1,5),(1,5),(1,5),(1,5)]\n",
        "types = [\"color\",\"pet\",\"drink\", \"country\",\"brand\"]\n",
        "\n",
        "\n",
        "problem_data = {\n",
        "  id: {\n",
        "      \"domain\": vars_domains[id-1],\n",
        "       \"type\": vars_types[id-1],\n",
        "       \"name\": vars_names[id-1]\n",
        "  } for id in vars_ids\n",
        "}\n",
        "\n",
        "import operator\n",
        "def eqDist1(x,y):\n",
        "\n",
        "  return operator.eq(operator.abs(operator.sub(x,y)), 1)\n",
        "\n",
        "def neDist1(x,y):\n",
        "\n",
        "  return operator.ne(operator.abs(operator.sub(x,y)), 1)\n",
        "\n",
        "\n",
        "vals = [1,2,3,4,5]\n",
        "ops = [operator.ge,operator.le,operator.lt,operator.gt,operator.ne,operator.eq]\n",
        "\n",
        "\n",
        "def eqConst(x, const):\n",
        "  return operator.eq(x,const)\n",
        "\n",
        "def geConst(x, const):\n",
        "  return operator.ge(x,const)\n",
        "\n",
        "def leConst(x, const):\n",
        "  return operator.le(x,const)\n",
        "\n",
        "def ltConst(x, const):\n",
        "  return operator.lt(x,const)\n",
        "\n",
        "def gtConst(x, const):\n",
        "  return operator.gt(x,const)\n",
        "\n",
        "def neConst(x, const):\n",
        "  return operator.ne(x,const)\n",
        "\n",
        "\n",
        "cpt=0\n",
        "while(cpt<=9):\n",
        "\n",
        "  constraints = []\n",
        "\n",
        "  indicesDiff = [\n",
        "      (1,2),\n",
        "      (1,3),\n",
        "      (1,4),\n",
        "      (1,5),\n",
        "      (2,3),\n",
        "      (2,4),\n",
        "      (2,5),\n",
        "      (3,4),\n",
        "      (3,5),\n",
        "      (4,5),\n",
        "      (6,7),\n",
        "      (6,8),\n",
        "      (6,9),\n",
        "      (6,10),\n",
        "      (7,8),\n",
        "      (7,9),\n",
        "      (7,10),\n",
        "      (8,9),\n",
        "      (8,10),\n",
        "      (9,10),\n",
        "      (11,12),\n",
        "      (11,13),\n",
        "      (11,14),\n",
        "      (11,15),\n",
        "      (12,13),\n",
        "      (12,14),\n",
        "      (12,15),\n",
        "      (13,14),\n",
        "      (13,15),\n",
        "      (14,15),\n",
        "      (16,17),\n",
        "      (16,18),\n",
        "      (16,19),\n",
        "      (16,20),\n",
        "      (17,18),\n",
        "      (17,19),\n",
        "      (17,20),\n",
        "      (18,19),\n",
        "      (18,20),\n",
        "      (19,20),\n",
        "      (21,22),\n",
        "      (21,23),\n",
        "      (21,24),\n",
        "      (21,25),\n",
        "      (22,23),\n",
        "      (22,24),\n",
        "      (22,25),\n",
        "      (23,24),\n",
        "      (23,25),\n",
        "      (24,25)\n",
        "  ]\n",
        "\n",
        "  coords = []\n",
        "  line = 0\n",
        "\n",
        "  for p in indicesDiff:\n",
        "    ri = cpt\n",
        "    cons = re.sub(\"!ELM1!\",problem_data[p[0]][\"name\"],phrasesNotEqual[ri])\n",
        "    cons = re.sub(\"!ELM2!\",problem_data[p[1]][\"name\"],cons)\n",
        "    constraints.append(cons)\n",
        "    coords.append({\n",
        "        \"scope\":p ,\n",
        "        \"rel\": operator.ne,\n",
        "        \"indice\":line\n",
        "    })\n",
        "    line+=1\n",
        "\n",
        "\n",
        "  indicesEq = [\n",
        "      (16,1),\n",
        "      (17,6),\n",
        "      (11,2),\n",
        "      (18,12),\n",
        "      (21,7),\n",
        "      (22,4),\n",
        "      (24,14),\n",
        "      (20,25)\n",
        "  ]\n",
        "\n",
        "  for p in indicesEq:\n",
        "    ri = cpt\n",
        "    cons = re.sub(\"!ELM1!\",problem_data[p[0]][\"name\"],phrasesEqual[ri])\n",
        "    cons = re.sub(\"!ELM2!\",problem_data[p[1]][\"name\"],cons)\n",
        "    constraints.append(cons)\n",
        "\n",
        "    coords.append({\n",
        "        \"scope\":p ,\n",
        "        \"rel\": operator.eq,\n",
        "        \"indice\":line\n",
        "    })\n",
        "    line+=1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  indicesGt = [\n",
        "      (2,3)\n",
        "  ]\n",
        "\n",
        "  for p in indicesGt:\n",
        "    ri = cpt\n",
        "    cons = re.sub(\"!ELM1!\",problem_data[p[0]][\"name\"],phrasesGreaterThan[ri])\n",
        "    cons = re.sub(\"!ELM2!\",problem_data[p[1]][\"name\"],cons)\n",
        "    constraints.append(cons)\n",
        "\n",
        "    coords.append({\n",
        "        \"scope\":p ,\n",
        "        \"rel\": operator.gt,\n",
        "        \"indice\":line\n",
        "    })\n",
        "    line+=1\n",
        "\n",
        "\n",
        "  indicesEqDist1 = [\n",
        "      (2,3),\n",
        "      (23,8),\n",
        "      (22,9),\n",
        "      (19,5)\n",
        "  ]\n",
        "\n",
        "  for p in indicesEqDist1:\n",
        "    ri = cpt\n",
        "    dist1 = re.sub(\"!ELM1!\",problem_data[p[0]][\"name\"],phrasesDistance[ri])\n",
        "    dist1 = re.sub(\"!ELM2!\",problem_data[p[1]][\"name\"],dist1)\n",
        "    cons = re.sub(\"!ELM1!\",dist1,phrasesEqual[ri])\n",
        "    cons = re.sub(\"!ELM2!\",\"1\",cons)\n",
        "    constraints.append(cons)\n",
        "\n",
        "    coords.append({\n",
        "        \"scope\":p,\n",
        "        \"rel\": eqDist1,\n",
        "        \"indice\":line\n",
        "    })\n",
        "    line+=1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  otherconstraints = [\n",
        "      (13, eqConst,3),\n",
        "      (19, eqConst,1)\n",
        "  ]\n",
        "\n",
        "  for p in otherconstraints:\n",
        "    ri = cpt\n",
        "    cons = re.sub(\"!ELM1!\",problem_data[p[0]][\"name\"],phrasesEqual[ri])\n",
        "    cons = re.sub(\"!ELM2!\",str(p[2]),cons)\n",
        "    constraints.append(cons)\n",
        "\n",
        "    coords.append({\n",
        "        \"scope\":(p[0],),\n",
        "        \"rel\": eqConst,\n",
        "        \"param\": [p[2]],\n",
        "        \"indice\":line\n",
        "    })\n",
        "    line+=1\n",
        "\n",
        "\n",
        "  with open(\"constraintsNLPzebra\"+str(cpt+1)+\".txt\", \"w\") as f:\n",
        "    for c in range(len(constraints)):\n",
        "      if(c<len(constraints)-1):\n",
        "        f.write(constraints[c]+\"\\n\")\n",
        "      else:\n",
        "        f.write(constraints[c])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  cpt+=1\n"
      ],
      "metadata": {
        "id": "8LaVtilPg4ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"zebraCoods.txt\", \"wb\") as f:\n",
        "  pickle.dump(coords, f)"
      ],
      "metadata": {
        "id": "lM7AKo0jkH5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Golomb"
      ],
      "metadata": {
        "id": "YAZgVEgdtlA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "n = 8\n",
        "ub = n * n + 1\n",
        "\n",
        "vars_ids =   [i+1 for i in range(n)]\n",
        "vars_names = [\"m\"+str(i+1) for i in range(n)]\n",
        "vars_types = [\"marker\" for i in range(n)]\n",
        "vars_domains = [(0,0)]\n",
        "vars_domains = vars_domains + [(1,ub) for i in range(n-1)]\n",
        "types = [\"marker\"]\n",
        "\n",
        "\n",
        "problem_data = {i+1: {\"domain\": (1,ub), \"name\": \"m\"+str(i+1),\"type\": \"marker\"} for i in range(n)}\n",
        "problem_data[1][\"domain\"] = (0,0)\n",
        "print(problem_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def eqDist(a,b,c,d):\n",
        "  return operator.eq( operator.abs(operator.sub(a,b)) ,  operator.abs(operator.sub(c,d)))\n",
        "\n",
        "def neDist(a,b,c,d):\n",
        "  return operator.ne( operator.abs(operator.sub(a,b)) ,  operator.abs(operator.sub(c,d)))\n",
        "\n",
        "\n",
        "def eqDist3(repeat,b,c):\n",
        "  return operator.eq( operator.abs(operator.sub(repeat,b)) ,  operator.abs(operator.sub(c,repeat)))\n",
        "\n",
        "def neDist3(repeat,b,c):\n",
        "  return operator.ne( operator.abs(operator.sub(repeat,b)) ,  operator.abs(operator.sub(c,repeat)))\n",
        "\n",
        "\n",
        "\n",
        "cpt=0\n",
        "\n",
        "while(cpt<=9):\n",
        "\n",
        "  constraints = []\n",
        "\n",
        "  coords = []\n",
        "  line = 0\n",
        "\n",
        "  # there is an increasing constraint between markers\n",
        "\n",
        "\n",
        "\n",
        "  for i in range(n-1):\n",
        "    #targetconstraints.append(Constraint([vars_ids[i],vars_ids[i+1]], operator.lt, 2,False))\n",
        "\n",
        "    ri = cpt\n",
        "\n",
        "    cons = re.sub(\"!ELM1!\",problem_data[vars_ids[i]][\"name\"],phrasesLessThan[ri])\n",
        "    cons = re.sub(\"!ELM2!\",problem_data[vars_ids[i+1]][\"name\"], cons)\n",
        "\n",
        "    constraints.append(cons)\n",
        "\n",
        "    coords.append({\n",
        "        \"scope\": (vars_ids[i],vars_ids[i+1]) ,\n",
        "        \"rel\": operator.lt,\n",
        "        \"indice\":line\n",
        "    })\n",
        "    line+=1\n",
        "\n",
        "  distances = list(combinations(range(1,n+1), 2))\n",
        "\n",
        "\n",
        "\n",
        "  for i in range(len(distances)-1):\n",
        "    for j in range(i+1,len(distances)):\n",
        "      p = list(distances[i])+list(distances[j])\n",
        "      pp = np.array(p)\n",
        "\n",
        "\n",
        "      ri = cpt\n",
        "      dist1 = re.sub(\"!ELM1!\",problem_data[p[0]][\"name\"],phrasesDistance[ri])\n",
        "      dist1 = re.sub(\"!ELM2!\",problem_data[p[1]][\"name\"],dist1)\n",
        "\n",
        "      dist2 = re.sub(\"!ELM1!\",problem_data[p[2]][\"name\"],phrasesDistance[ri])\n",
        "      dist2 = re.sub(\"!ELM2!\",problem_data[p[3]][\"name\"],dist2)\n",
        "\n",
        "      cons = re.sub(\"!ELM1!\",dist1,phrasesNotEqual[ri])\n",
        "      cons = re.sub(\"!ELM2!\",dist2,cons)\n",
        "      constraints.append(cons)\n",
        "\n",
        "      if(len(np.unique(pp)) == len(pp)):\n",
        "        coords.append({\n",
        "        \"scope\": p,\n",
        "        \"rel\": neDist,\n",
        "        \"indice\":line\n",
        "        })\n",
        "        line+=1\n",
        "      else:\n",
        "        if(p[0]==p[2]):\n",
        "          #targetconstraints.append(Constraint([], neDist3 , 3,False))\n",
        "          coords.append({\n",
        "              \"scope\": (p[0],p[1],p[3]),\n",
        "              \"rel\": neDist3,\n",
        "              \"indice\":line\n",
        "          })\n",
        "          line+=1\n",
        "        elif(p[0]==p[3]):\n",
        "          coords.append({\n",
        "              \"scope\": (p[0],p[1],p[2]),\n",
        "              \"rel\": neDist3,\n",
        "              \"indice\":line\n",
        "          })\n",
        "          line+=1\n",
        "\n",
        "        elif(p[1]==p[2]):\n",
        "          coords.append({\n",
        "              \"scope\": (p[1],p[0],p[3]),\n",
        "              \"rel\": neDist3,\n",
        "              \"indice\":line\n",
        "          })\n",
        "          line+=1\n",
        "\n",
        "        elif(p[1]==p[3]):\n",
        "          coords.append({\n",
        "              \"scope\": (p[1],p[0],p[2]),\n",
        "              \"rel\": neDist3,\n",
        "              \"indice\":line\n",
        "          })\n",
        "          line+=1\n",
        "\n",
        "\n",
        "  with open(\"constraintsNLPgolomb\"+str(cpt+1)+\".txt\", \"w\") as f:\n",
        "    for c in range(len(constraints)):\n",
        "      if(c< len(constraints)-1):\n",
        "        f.write(constraints[c]+\"\\n\")\n",
        "      else:\n",
        "        f.write(constraints[c])\n",
        "\n",
        "  cpt+=1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rfFFSSRtmjr",
        "outputId": "fe24f29a-55cb-4300-b68d-09cfa4e6b15a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: {'domain': (0, 0), 'name': 'm1', 'type': 'marker'}, 2: {'domain': (1, 65), 'name': 'm2', 'type': 'marker'}, 3: {'domain': (1, 65), 'name': 'm3', 'type': 'marker'}, 4: {'domain': (1, 65), 'name': 'm4', 'type': 'marker'}, 5: {'domain': (1, 65), 'name': 'm5', 'type': 'marker'}, 6: {'domain': (1, 65), 'name': 'm6', 'type': 'marker'}, 7: {'domain': (1, 65), 'name': 'm7', 'type': 'marker'}, 8: {'domain': (1, 65), 'name': 'm8', 'type': 'marker'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"golombCoods.txt\", \"wb\") as f:\n",
        "  pickle.dump(coords, f)"
      ],
      "metadata": {
        "id": "Gil4v1kFvP_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Purdey"
      ],
      "metadata": {
        "id": "cx-fBlfhibkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vars_ids =   [   1     ,   2     ,  3      ,  4     ,   5     ,  6      ,    7     ,   8     ,    9  ,   10  ,   11   ,  12]\n",
        "vars_names = [\"family1\",\"family2\",\"family3\",\"family4\",\"bought1\",\"bought2\",\"bought3\",\"bought4\",\"paid1\",\"paid2\",\"paid3\",\"paid4\"]\n",
        "vars_types = [\"family\",\"family\",\"family\",\"family\",\"bought\",\"bought\",\"bought\",\"bought\",\"paid\",\"paid\",\"paid\",\"paid\"]\n",
        "vars_domains = [(1,4),(1,4),(1,4),(1,4),(1,4),(1,4),(1,4),(1,4),(1,4),(1,4),(1,4),(1,4)]\n",
        "types = [\"family\",\"bought\",\"paid\"]\n",
        "\n",
        "\n",
        "problem_data = {\n",
        "  id: {\n",
        "      \"domain\": vars_domains[id-1],\n",
        "       \"type\": vars_types[id-1],\n",
        "       \"name\": vars_names[id-1]\n",
        "  } for id in vars_ids\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "indicesGt = [\n",
        "   (1,5), #\"family1 should be greater than bought1\",\n",
        "    (5,7), #\"bought1 should be greater than bought3\",\n",
        "    (5,8) #\"bought1 must be greater than bought4\",\n",
        " ]\n",
        "\n",
        "indicesLt = [\n",
        "    (12,10) #\"paid4 should be less than paid2\",\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "indicesEq = [\n",
        "    (5,11), #\"bought1 must be equal to paid3\",\n",
        "    (3,5), #\"family3 must be equal to bought1\",\n",
        "    (8,12), #\"bought4 should be equal to paid4\",\n",
        "    (2,7), #\"family2 should be equal to bought3\",\n",
        "    (7,10), #\"bought3 must be equal to paid2\"\n",
        "]\n",
        "\n",
        "indicesDiff = [\n",
        "      (1,2), #\"family1 should be different than family2\",\n",
        "      (1,3),  #\"family1 must be different than family3\",\n",
        "      (1,4),  # \"family1 must be different than family4\",\n",
        "      (2,3),  # \"family2 should be different than family3\",\n",
        "      (2,4),  # \"family2 should be different than family4\",\n",
        "      (3,4),  # \"family3 must be different than family4\",\n",
        "      (5,6),  # \"bought1 should be different than bought2\",\n",
        "      (5,7),  # \"bought1 should be different than bought3\",\n",
        "      (5,8),  # \"bought1 must be different than bought4\",\n",
        "      (6,7),  # \"bought2 should be different than bought3\",\n",
        "      (6,8),  # \"bought2 should be different than bought4\",\n",
        "      (7,8),  # \"bought3 should be different than bought4\",\n",
        "      (9,10),  # \"paid1 must be different than paid2\",\n",
        "      (9,11),  # \"paid1 should be different than paid3\",\n",
        "      (9,12),  # \"paid1 should be different than paid4\",\n",
        "      (10,11),  # \"paid2 should be different than paid3\",\n",
        "      (10,12),  # \"paid2 should be different than paid4\",\n",
        "      (11,12) # \"paid3 should be different than paid4\",\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "cpt = 0\n",
        "\n",
        "\n",
        "while(cpt<=9):\n",
        "  constraints = []\n",
        "  coords = []\n",
        "  line = 0\n",
        "\n",
        "\n",
        "\n",
        "  for p in indicesDiff:\n",
        "    ri = cpt\n",
        "    cons = re.sub(\"!ELM1!\",problem_data[p[0]][\"name\"],phrasesNotEqual[ri])\n",
        "    cons = re.sub(\"!ELM2!\",problem_data[p[1]][\"name\"],cons)\n",
        "    constraints.append(cons)\n",
        "    coords.append({\n",
        "        \"scope\":p ,\n",
        "        \"rel\": operator.ne,\n",
        "        \"indice\":line\n",
        "    })\n",
        "    line+=1\n",
        "\n",
        "\n",
        "\n",
        "  for p in indicesEq:\n",
        "    ri = cpt\n",
        "    cons = re.sub(\"!ELM1!\",problem_data[p[0]][\"name\"],phrasesEqual[ri])\n",
        "    cons = re.sub(\"!ELM2!\",problem_data[p[1]][\"name\"],cons)\n",
        "    constraints.append(cons)\n",
        "    coords.append({\n",
        "        \"scope\":p ,\n",
        "        \"rel\": operator.eq,\n",
        "        \"indice\":line\n",
        "    })\n",
        "    line+=1\n",
        "\n",
        "\n",
        "  for p in indicesGt:\n",
        "    ri = cpt\n",
        "    cons = re.sub(\"!ELM1!\",problem_data[p[0]][\"name\"],phrasesGreaterThan[ri])\n",
        "    cons = re.sub(\"!ELM2!\",problem_data[p[1]][\"name\"],cons)\n",
        "    constraints.append(cons)\n",
        "    coords.append({\n",
        "        \"scope\":p ,\n",
        "        \"rel\": operator.gt,\n",
        "        \"indice\":line\n",
        "    })\n",
        "    line+=1\n",
        "\n",
        "\n",
        "  for p in indicesLt:\n",
        "    ri = cpt\n",
        "    cons = re.sub(\"!ELM1!\",problem_data[p[0]][\"name\"],phrasesLessThan[ri])\n",
        "    cons = re.sub(\"!ELM2!\",problem_data[p[1]][\"name\"],cons)\n",
        "    constraints.append(cons)\n",
        "    coords.append({\n",
        "        \"scope\":p ,\n",
        "        \"rel\": operator.lt,\n",
        "        \"indice\":line\n",
        "    })\n",
        "    line+=1\n",
        "\n",
        "\n",
        "  with open(\"constraintsNLPpurdey\"+str(cpt+1)+\".txt\", \"w\") as f:\n",
        "    for c in range(len(constraints)):\n",
        "      if(c< len(constraints)-1):\n",
        "        f.write(constraints[c]+\"\\n\")\n",
        "      else:\n",
        "        f.write(constraints[c])\n",
        "\n",
        "\n",
        "  cpt+=1"
      ],
      "metadata": {
        "id": "7bnn7gDrvS1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"purdeyCoods.txt\", \"wb\") as f:\n",
        "  pickle.dump(coords, f)"
      ],
      "metadata": {
        "id": "tSsYhG2Dm7c7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# download"
      ],
      "metadata": {
        "id": "dkLiAl-HqvMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip testfiles.zip *.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN3kAs2-qwoc",
        "outputId": "7b694583-cae4-4818-f0cd-879239255d93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: constraintsNLPgolomb10.txt (deflated 97%)\n",
            "  adding: constraintsNLPgolomb1.txt (deflated 96%)\n",
            "  adding: constraintsNLPgolomb2.txt (deflated 96%)\n",
            "  adding: constraintsNLPgolomb3.txt (deflated 97%)\n",
            "  adding: constraintsNLPgolomb4.txt (deflated 95%)\n",
            "  adding: constraintsNLPgolomb5.txt (deflated 96%)\n",
            "  adding: constraintsNLPgolomb6.txt (deflated 97%)\n",
            "  adding: constraintsNLPgolomb7.txt (deflated 97%)\n",
            "  adding: constraintsNLPgolomb8.txt (deflated 97%)\n",
            "  adding: constraintsNLPgolomb9.txt (deflated 97%)\n",
            "  adding: constraintsNLPjigsaw10.txt (deflated 94%)\n",
            "  adding: constraintsNLPjigsaw1.txt (deflated 91%)\n",
            "  adding: constraintsNLPjigsaw2.txt (deflated 92%)\n",
            "  adding: constraintsNLPjigsaw3.txt (deflated 90%)\n",
            "  adding: constraintsNLPjigsaw4.txt (deflated 92%)\n",
            "  adding: constraintsNLPjigsaw5.txt (deflated 91%)\n",
            "  adding: constraintsNLPjigsaw6.txt (deflated 93%)\n",
            "  adding: constraintsNLPjigsaw7.txt (deflated 93%)\n",
            "  adding: constraintsNLPjigsaw8.txt (deflated 93%)\n",
            "  adding: constraintsNLPjigsaw9.txt (deflated 93%)\n",
            "  adding: constraintsNLPpurdey10.txt (deflated 84%)\n",
            "  adding: constraintsNLPpurdey1.txt (deflated 83%)\n",
            "  adding: constraintsNLPpurdey2.txt (deflated 84%)\n",
            "  adding: constraintsNLPpurdey3.txt (deflated 81%)\n",
            "  adding: constraintsNLPpurdey4.txt (deflated 83%)\n",
            "  adding: constraintsNLPpurdey5.txt (deflated 82%)\n",
            "  adding: constraintsNLPpurdey6.txt (deflated 83%)\n",
            "  adding: constraintsNLPpurdey7.txt (deflated 83%)\n",
            "  adding: constraintsNLPpurdey8.txt (deflated 84%)\n",
            "  adding: constraintsNLPpurdey9.txt (deflated 84%)\n",
            "  adding: constraintsNLPsuduku10.txt (deflated 94%)\n",
            "  adding: constraintsNLPsuduku1.txt (deflated 91%)\n",
            "  adding: constraintsNLPsuduku2.txt (deflated 92%)\n",
            "  adding: constraintsNLPsuduku3.txt (deflated 90%)\n",
            "  adding: constraintsNLPsuduku4.txt (deflated 92%)\n",
            "  adding: constraintsNLPsuduku5.txt (deflated 91%)\n",
            "  adding: constraintsNLPsuduku6.txt (deflated 93%)\n",
            "  adding: constraintsNLPsuduku7.txt (deflated 93%)\n",
            "  adding: constraintsNLPsuduku8.txt (deflated 93%)\n",
            "  adding: constraintsNLPsuduku9.txt (deflated 93%)\n",
            "  adding: constraintsNLPzebra10.txt (deflated 87%)\n",
            "  adding: constraintsNLPzebra1.txt (deflated 84%)\n",
            "  adding: constraintsNLPzebra2.txt (deflated 84%)\n",
            "  adding: constraintsNLPzebra3.txt (deflated 82%)\n",
            "  adding: constraintsNLPzebra4.txt (deflated 83%)\n",
            "  adding: constraintsNLPzebra5.txt (deflated 83%)\n",
            "  adding: constraintsNLPzebra6.txt (deflated 85%)\n",
            "  adding: constraintsNLPzebra7.txt (deflated 86%)\n",
            "  adding: constraintsNLPzebra8.txt (deflated 86%)\n",
            "  adding: constraintsNLPzebra9.txt (deflated 86%)\n",
            "  adding: golombCoods.txt (deflated 79%)\n",
            "  adding: jigsawCoods.txt (deflated 80%)\n",
            "  adding: purdeyCoods.txt (deflated 62%)\n",
            "  adding: sudukuCoods.txt (deflated 81%)\n",
            "  adding: zebraCoods.txt (deflated 68%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wrJORPaQq4GK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}